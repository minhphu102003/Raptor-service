# JOHN D.C. LITTLE

In the past 10 years, a new technology has emerged for assisting and

improving marketing decision making. We define a marketing deci-

sion support system us a coordinated collection of data, models,

analytic tools, and computing power by which an organization

gathers information from the environment and turns it into a basis for

action. Where such systems have taken root, they have grown and

become increasingly productive for their organizations.

# DECISION SUPPORT SYSTEMS

# FOR MARKETING MANAGERS
THE combination of large potential payoffs, highly What is It? A Black Box View

motivated professional staffs, evolving OR/MS A manager takes action with respect to an environment

techniques, and rising computer power is making an in order to achieve the objectives of his organization.

impact on marketing management. A problem-solving To do this he must perceive and interpret the market,

technology is emerging that consists of people, knowl- even if imperfectly. Then he must think up strategies,

edge, software, and hardware successfully wired into analyze them, and converge on one to put into practice.

the management process. Following Gorry and Scott This process is conducted through a complicated sys-

Morton (1971), we shall call the set of facilitating tools tem of people, paper, and machines. We call the inani-

a decision support system or, more specifically a Mar- mate part of this an MDSS. Figure 1, modified from

keting Decision Support System (MDSS). Intellectual Montgomery and Urban (1969), shows the MDSS and

contributions to MDSS have come from many disci- its components and traces their roles in interpreting and

plines: OR/MS, marketing research, computer science, analyzing the environment.

behavioral science, and statistics, to name a few. We

view the results collectively as an advance in manage- Data Bank. A stream of information comes into the

ment science or, more specifically marketing science. organization from the world at large in many ways:

Our purpose is to define and illustrate the concept of an from members of the organization; from talking to

MDSS and show its effects on marketing practice. people; from reading the Wall Street Journal; from

purchasing market research; and especially from dis-

tilling the multitude of individual transactions of the

business—orders, shipments, purchases, records of

internal action, and much more. The data are stored in

varied forms: on paper, in people's heads, and, most

relevant for our present purposes, in large chunks on

machine readable media. The amount of data handled

by a large company is staggering. Business runs on

John D.C. Little is the George Maverick Bunker Professor of

Management, Sloan School of Management, Massachusetts

Institute of Technology, Cambridge, MA. The author wishes to

thank the staff of Management Decision Systems, Inc. for

providing many opportunities to learn about live decision sup-

port systems.

FIGURE 1

A manager uses a marketing decision support sys-

tem (MDSS) to learn about the business environ-

ment and take action with respect to it.

This figure is a diagram illustrating the flow of information and action in a marketing decision support system (MDSS). It shows a manager at the top, connected to various components such as models, statistics, optimization, data, and the environment. Arrows indicate the flow of information and influence between these components. The manager takes action based on the information received from these components, and the environment provides feedback that influences the manager's decisions.

numbers. Sales alone have vast detail, and might, for

example, be broken out by time period, market area,

brand, package size, salesperson, and customer. How

did people get along before computers? (Quite well,

thank you, but they missed many profit opportunities

open to us now.)

Less obvious than the flood of data washing over

companies is the information they do not have. Often

they may have it in principle, but not in practice. For

example, I recently asked a large and successful com-

pany for the following data, which they could not

supply: product category sales by month and major

market area, competitive advertising, and even more

surprising, the company's own promotional spending

by market area. At another company, I once sought

advertising expenditures by month, but they could only

be provided in terms of when the bills were paid, not

when the advertising was run. This was not too helpful

for marketing analysis. Certain data are simply not

gathered, others are aggregated and the original detail

lost or prohibitively costly to recover. Competitive data

usually comes from syndicated services as hard copy

which is inadequate for any, but the most aggregate

analysis.

Clearly, a basic task of any MDSS is to capture

major marketing variables such as sales, advertising,

promotion, and price in reasonable detail and truly

accessible form. Remarkably few companies do an

adequate job today. The issue is cost and therefore

value, since data for data's sake is a worthless luxury. It

takes skillful analysis and effective coupling with man-

agement to provide the benefits that justify the cost, but

the payback can be large.

Models. Whenever a manager (or anybody else)

looks at data, he or she has a preconceived idea of how

the world works and therefore of what is interesting and

worthwhile in the data. We shall call such ideas models.

Even a person who is browsing through tables has a set

of constructs in mind that signal when a particular

number is important and worth further consideration.

Thus, a manager or management scientist uses theories

to determine what aggregations or manipulations are

meaningful for the decision at hand. The data user may

want to confirm or disprove a hypothesis, guide an

action, or learn the magnitude of a past number so as to

judge the reasonableness of a current one. Manipula-

tion of the numbers may cause an old theory to be

discarded and a new one created to conform better to the

facts.

Soine models remain in people's heads, but the

ones of most interest here are those that find explicit

mathematical and computational representation.

These aid planning, decision making, and many less

publicized supporting tasks required for understanding

and analyzing the market.

Statistics. We shall call the process of relating mod-

els to data statistics. The most important statistical

operation is addition. This makes big important num-

bers out of small, trivial ones. Many sophisticated

techniques also are available for model and hypothesis

testing and they often prove useful. However, it is not

widely realized, except by those with their hands on the

data, that the most frequent operations are basic ones

like segregating numbers into groups, aggregating

them, taking ratios, making comparisons, picking out

exceptional cases, plotting, tabulating summaries, etc.

These manipulations are required by such standard

managerial models as proforma profit and loss state-

ments, budgeting, and forecasting, to say nothing of

more complicated models for new product tracking,

marketing-mix planning, and the like.

Optimization. A manager constantly seeks to im-

prove the performance of his organization. Abstractly

this is optimization. The most frequent operations are

deceptively simple: calculating two numbers and see-

ing which is larger, ranking a set of numbers, or sorting

a set of alternatives into categories of effectiveness. In

addition, there are many cases where formal OR/MS

optimization methods such as linear programming and

its extensions offer substantial payoffs.

*Q/A.* Finally, the manager and his or her staff must

communicate with the system. Insofar as the required

skills, talent, and information are distributed through-

out the organization, communication involves the stan-

dard processes of meetings, studies, and reports. As the

systems become formal and automated, some of the

communication takes place through interactive time-

shared computing. Individual tools are stored as com-

puter programs. With the right software, data and files

pass easily between analyses, and a management scien-

tist or other person can perform a wide scope of analysis

smoothly, quickly, and efficiently.

To summarize, a marketing decision support sys-

tem is a coordinated collection of data, systems, tools,

and techniques with supporting software and hardware

by which an organization gathers and interprets rele-

vant information from business and environment and

turns it into a basis for marketing action.
# The Critics

We have described the concept, but what about the

practice? Management science has its critics. Let's see

what C. Jackson Grayson Jr. (1973) says in the *Har-

vard Business Review*. Grayson, a Harvard DBA, au-

thor of a book applying decision analysis to oil drilling

decisions, former dean of a business school, and cur-

rently head of a productivity institute, writes:

> Management Science has grown so remote from and unmind-

> ful of the conditions of "live" management that it has abdi-

> cated its usability.

We would like to dismiss this as an isolated com-

plaint, not likely to be repeated. But wait, let's see what

John D.C. Little (1970), professor of Operations Re-

search and Management at M.I.T., says in *Manage-

ment Science*:

> The big problem with management science models is that

> managers practically never use them.

This situation must be serious! On close examina-

tion, however, Grayson's article and mine are quite

different in content and tone. Grayson reports that in the

most important administrative role of his career

(Chairman of the U.S. Price Commission), he found no

use for his management science training. He goes on to

describe managers generally as confused and dissatis-

fied with management science activities in their organi-

zations and admonishes management scientists and

managers to build bridges to each other. One can hardly

advocate that they should not, but this proposal seems

patronizing at best and indicates an ignorance of a great

deal of useful work that has gone on.

My own paper, written three years earlier, sought to

draw on a variety of practical experiences to describe

"how-to-do-it" in building useful models. By 1970

much had been learned, sometimes by painful trial and

error, about doing OR/MS successfully in business and

government. Regrettably, good applications often lie

concealed because little incentive exists for their revela-

tion and, worse yet, strong forces favor secrecy. Fortu-

nately, studies are beginning to appear more regularly.

(See for example, the prize paper issues of *Interfaces*,

Nigam, 1975, 1976, 1977.)

OR/MS practitioners and marketing researchers

have continued to learn what works and what does not.

This paper tries to report some of this.
# How an MDSS Works. A True Story

The Marketing Manager, the Management Scientist

and the MBA

Once upon a time (1973), an MBA student took a

summer job with a large food manufacturer. He re-

ported to a management scientist in the principal divi-

sion of the company. The MBA was assigned to put key

marketing information, basically store audit data, on a

time-shared computer. The goal was an easy-to-use

retrieval system, essentially the DATA box of Figure 1.

O.K. He did this.

By the end of the summer, word of the system had

reached the marketing manager of the major product of

the division who asked for a demonstration and so the

three met. The MBA and the management scientist

showed the marketing manager how simple, English-

like commands could retrieve data items: sales, share,

price, distribution level, etc., each by brand, package

size, and month.

The marketing manager was impressed. "You must

be fantastically smart," he told the MBA. "The people

downstairs in MIS have been trying to do this for years

and they haven't gotten anywhere. You did it in a

summer."

It was hard for the MBA to reject this assessment

out of hand, but he did acknowledge, and this is a key

point, that the software world had changed. There are

now high level analytic languages available on time-

sharing that make it easy to bring up data and start

working on it right away.

The MBA and the management scientist, flushed

with success, now said to the marketing manager:

"O.K. Ask us anything!" (Famous last words.)

The marketing manager thought a minute and said:

"I'd like to know how much the competition's intro-

duction of a 40 oz. package in Los Angeles cut into the

sales of our 16 oz. package."

The MBA and the management scientist looked at

each other in dismay. What they realized right away,

and what you might too if you think about it, is that

there isn't going to be any number in the machine for

sales that didn't occur. This isn't a retrieval question at

all, it's an analysis question.

Here then is another point. The marketing manager

had no idea the number would not be in the machine. To

him it was just one more fact no different in his mind

from other facts about the market. Notice also that the

question is a reasonable one. One can visualize a whole

string of managerial acts that might be triggered by the

answer, possibly even culminating in the introduction

of a new package by the company.

What is needed to answer the question is a model,

probably a rather simple model. For example, one

might extrapolate previous share and use it to estimate

the sales that would have happened without the com-

petitor's introduction. Then subtraction of actual sales

would give the loss.

The three discussed possible assumptions for a few

minutes and agreed on how to approach the problem.

Then the management scientist typed in one line of high

level commands. Out came the result, expressed in

dollars, cases, and share points.

The marketing manager thought the answer was

fine, a good demonstration. The MBA and the man-

agement scientist thought it was a miracle! They had

responded to the question with a speed and accuracy

unthinkable a few months earlier.

The story is simple but contains several important

lessons. I see the same points coming up again and

again in various organizations, although not always so

neatly and concisely:

* Managers ask for analysis not retrieval. Some-

times retrieval questions come up of course, but

most often the answers to important questions

require nontrivial manipulation of stored data.

Knowing this tells us much about the kind of

software required for an MDSS. For example, a

data base management system is not enough.

* Good data are vital. If you haven't done your

homework and put key data on the system you

are nowhere. Thus, a powerful analytic language

alone is not enough.

* You need models. These are often simple, but not

always. Some can be prepackaged. Many are ad

hoc.

* The management scientist is an intermediary. He

connects the manager to the MDSS. The man-

ager does not use the system directly. The man-

agement scientist interprets questions, formu-

lates problems in cooperation with the manager,

creates models, and uses them to answer ques-

tions and analyze issues.

* Quick, quick, quick. If you can answer people's

questions right away, you will affect their think-

ing. If you cannot, they will make their decisions

without you and go on to something else.

* Muscular software cuts out programmers. New

high-level languages on time-sharing permit a

management scientist or recently trained MBA to

bring up systems and do analyses singlehand-

edly. This makes for efficient problem-solving.

Furthermore, the problem-solver identifies with

and deals directly with marketing management

so that his understanding and motivation are

high. Time-sharing costs more than batch pro-

cessing, but an army of programmers is elimi-

nated and, far more important, problems get

solved on time.
Decision Support for the Product Life

Cycle: Cradle to Grave Care

Let's look at marketing per se. Over the past 10 or 15

years and continuing unabated, there has evolved from

diverse origins a series of tools and techniques for

support of the product life cycle.

By product life cycle we mean a sequence of conve-

niently defined stages that describe the history of a

product from conception to possible demise. We do not

imply that every product goes through every stage or

that any stage lasts some prescribed length of time.

The product life cycle is illustrated in Figure 2. A

product starts as someone's bright idea, thereby iden-

tifying a category. The idea then goes through a stage of

concept and product development and evaluation, lead-

ing to a detailed design and market position. Develop-

ment and evaluation are closely linked; at various times

during development, evaluations of greater or lesser

depth will be made and the results fed back to refocus

development.

The next step is usually test market, although an

industrial product will not ordinarily have this step.

Then comes national introduction. In the ongoing

stage, the product becomes, one hopes, an established

and profitable business. From time to time a product

may go through a thorough revamping or "reintroduc-

tion." Many at some point go into a twilight of obsoles-

cence (the slide rule and the mechanical watch seem

headed this way). Finally many products including

quite a few former household names, go out of exis-

tence entirely. The tombstone in Figure 2 might read:

"Chrysler Imperial: 1926-1975, died at age 49 of sales starvation."

The mortality of new products has traditionally been notorious. For example, General Foods reported in Business Week (1973) a 15 year history in which 83% of new products did not get out of the idea

stage. Of those that did, 60% never reached test market; of those entering test market, 59% failed; and even among those making it to national introduction, 25% were consid- ered financial failures.

At the same time, new product introduction is very expensive. For a typical package good of a major manufacturer, the development and evaluation stage might cost $150,000; a test market, $1 million; a

national introduction, $5-10 million. A new industrial product would omit the test market expense, but might well spend an equivalent amount on devel- opment and evaluation.

Responding to the challenge of the heavy expenses and high profit aspirations of new products, marketing scientists have developed an array of methodologies and measurements to support decision

making at vari- ous stages of the life cycle.

At the idea and category selection stage, systematic search procedures drawn from behavioral science sup- plement traditional inspiration. Focus groups (Cox, Higginbotham, and Burton 1976) probe

customer feel- ings about needs and perceptions. "Synectics" (Prince 1972) is a technique whereby a group of people seek to solve a problem in an organized way, e.g., conceive of a product to meet a

specified set of customers needs. As demonstrated by von Hippel (1978) customers them- selves are an important source of industrial product ideas. Industrial and governmental data on potential markets

suggest new product opportunities. Environ- mental scanning can turn up danger spots for existing products and needs for new ones.

The bulk of the new techniques, however, begins to come into play at the next stage: development and

evaluation. Value-in-use analysis (Gross 1977) looks at a product from the customer's point of view and asks: "What advantages are there to the customer from using this product? What cost savings?

What time savings? What investment would be required to achieve this savings?" By answering such questions for each poten- tial market segment, an aggregate picture of volume versus price can be

synthesized.

A particularly well-articulated description of a for- mal new product design, development, and positioning methodology is that of Hauser and Urban (1977). Their normative design process envisages

first finding out the customer's words for talking about the product cate- gory. This might be done through focus groups. Then, customer words are developed into psychometric scales. Potential

customers use these scales to rate new and existing products in the category. As customers do this, they also express preferences among the products and so generate data that can be analyzed to

identify the customers' key utility dimensions. Such information permits the calibration of a model of new product share and sales. A feedback loop between model and man- ager facilitates the

modification of the product and its market position.

Other tools fit in at this stage of the life cycle, some within the Hauser-Urban framework. These include mapping studies, conjoint measurement, and consumer choice models. Mapping is a general term

to describe the visual representation of competitive products rela- tive to each other in a space of consumer perceptual dimensions. Conjoint measurement (Green and Wind 1975) presents alternative

product features to custom- ers in order to obtain their trade-offs and build new products with high market potential. Consumer choice models (Shocker and Srinivasan 1977; Hauser 1978) relate choice

to consumer utility or preference.

A particularly successful blend of models, mea- surements, and statistical techniques has emerged for

Figure illustrating the product life cycle. The cycle starts with an idea, then moves to development, evaluation, test market, introduction, ongoing, twilight, and finally rest in peace. There are feedback loops from evaluation back to development and from ongoing back to introduction. Below the main cycle are corresponding stages: select category, design position, check out, fine tune, monitor, grow, milk, and bite bullet.

pretest market evaluation. The best example is Silk and

Urban's ASSESSOR (1978). In their method, people

passing through a shopping mall are invited to partici-

pate in a marketing study. They view competing adver-

tising commercials including one for the new product

under test, and then have an opportunity to select a

brand from a shelf display containing the new product.

Data are taken by questionnaire stionnaire during the process and

later a telephone call-back determines the customer's

likelihood of repurchasing. This type of careful orches-

tration of psychometric scaling, consumer choice mod-

els, trial-repeat purchase models, and statistical calibra-

tion has proven extremely useful to marketers of pack-

age goods and holds the promise of extension to new

areas, e.g., pharmaceuticals and small durables.

As we move on to test marketing and national

introduction, the techniques change. The principal

tools become trial-repeat models calibrated by store

audits, ad hoc surveys, and consumer diary panels. The

task is to follow the buildup of consumer trial and

repurchase and project to future sales and share. Parfitt

and Collins (1968) provide a simple model and Urban

(1970) in SPRINTER a comprehensive model for doing

this. As pretest market evaluations increasingly elimi-

nate costly failures, test marketing becomes more of a

fine-tuning for the marketing mix than a go/no-go test.

Therefore, new product tracking models that contain

major control variables become most useful.

At the established brand stage, the picture changes

again. Ongoing brands frequently take a back seat as

new products consume managerial attention. Yet for

many companies, this is a mistake since major profit

opportunities often lie with the old breadwinners. Mar-

ket response analyses assisted by marketing-mix mod-

els like Little's (1975) BRANDAID or Bloom and

Stewart's (1977) MAPLAMOD harness major control

variables such as price, promotion, and advertising for

strategy planning and permit tracking predicted versus

actual sales. Discrepancies lead to diagnosis of market

problems. Econometric analysis of historical data (Par-

sons and Schultz 1976; Bass and Clarke 1972) can help

calibrate such models. Consumer panel analyses like

those of Ehrenberg (1972) can detect customer pur-

chase shifts. Individual models of price, promotion,

and advertising are frequently useful for specific tacti-

cal problems.

The basic information sources are also different in

the ongoing stage since product management relies

more heavily on continuing data: factory shipments;

promotion reports; advertising expenses; and syndi-

cated services such as store audits, warehouse with-

drawals, and consumer panels. These services are well

developed in consumer package goods, spotty in con-

sumer durables, and almost absent in industrial mar-

kets.

The twilight or obsolescence stage also has attracted

effort. For example, Hess (1967) discusses the pricing

of new and old products when the new is destined to

supplant the old. The final phasing out of a product

from a product line is studied as part of product

portfolio analyses (Day 1977).

Thus every part of the product life cycle has gener-

ated marketing science activity. Some efforts are more

extensive and more successful than others in affecting

practice, but it is clear that changes are afoot.
# Marketing Science: Who is

Kidding Whom?

I like to use the term "marketing science." However,

the phiase makes some people flinch and others stir

restlessly. Is what we have described an advance in

fundamental understanding or is it merely a series of

commercial fads? Can we sensibly talk about science in

a flamboyant field where the motivation and funding

are so far from the usual domain of the natural philoso-

pher? 1 shall argue that we are indeed engaged in sci-

ence.

First, it should be observed that most of the actors

on the marketing stage are not scientists. Many are

skillful performing artists and very successful, but not

scientists any more than, say, a sculptor is. But when a

sculptor hammers a chisel into a piece of marble, he

initiates a process that is well described by the laws of

physics. In marketing we are not so far along.

Are we anywhere? Natural science is concerned

with understanding how the world works. This means

models and measurements, the twin engines of scien-

tific advance. Models provide structure for de-

scribing phenomena and permit knowledge to be more

than an encyclopedia of facts. Measurements separate

good models from bad and allow good ones to be

calibrated for practical application. It seems obvious

that you can make a scientific study of any observable

phenomenon and that we are certainly doing that on

many occasions in marketing.

Whereas understanding is the province of science,

application is the domain of technology. Common

usage expands science to cover both. (Thus: "Science

put men on the moon, why can't it cure the common

cold?") The dividing line is blurred and we shall follow

the common usage, but identify understanding as the

essential ingredient of science.

Two characteristics of marketing practice tend to

obscure accomplishments in fundamental understand-

ing. First, application regularly oversteps knowledge, a

situation that makes for confusion, since truths are

often proclaimed that are not true. I used to read articles

in the business press about marketing successes and

marvel that people knew so much more about their

markets than I was able to discover by analysis. Eventually I realized that the authors were using different standards of knowing. What was being written reflected the fact that businessmen often

make good decisions with relatively poor information. As part of the process, they usually make assertive statements whether or not they possess firm knowledge. In any case, businessmen much prefer to

have knowledge and would like us to give it to them wherever possible.

The second point is that, because so much marketing data collection, analysis, and model building is bent toward specific decisions, underlying discoveries are frequently the spinoff of the

application, rather than the reverse. On the way to solving a practical problem, people often develop new understanding. This certainly isn't novel in science-probability, for example, was born at the

gaming tables. Not all marketing studies produce scientific knowledge-most are not done nearly carefully enough but the potential is there and sometimes the realization. The marketing papers appearing

in *Management Science, Operations Research,* and *Journal of Marketing Research* over the past 15 years demonstrate the quality of the work and the vitality of the field.

Thus, we view marketing science as real. It is an applications-driven subject that is building a base of understanding about marketing processes.

Figure 3 shows a line graph titled "SALES". The x-axis is labeled "TIME (4 WEEK PERIODS)" and ranges from 1 to 34. The y-axis ranges from 0 to 1.4. There are two horizontal lines indicating "AVERAGE DURING HEAVY ADVERTISING" and "PRETEST AVERAGE". There are two vertical dashed lines indicating "HEAVY ADVERTISING". The graph shows sales increasing during the heavy advertising period and then slowly declining after the advertising is removed.
Measurements

Measurements are contact points with reality, they generate the excitement of new discovery and practical payoff more often than models. Companies pay a great deal for measurements. Syndicated

services in store audits, diary panels, media ratings, and the like constitute at least a $200 million industry per year in the United States. Ad hoc surveys, copy tests, etc., reach a comparable

dollar magnitude.

Measurements motivated by theories and models are most valuable. For example, Figure 3 shows the results of an advertising test. Sales are plotted versus time before, during, and after a heavy-up of

advertising.

The results are striking. Notice the rapid rise, leveling off, and slow decay. The data cry out for a theory and more measurement. Why do sales go up quickly and down slowly? What would happen if the

same test were repeated in the same areas a year later? Clearly Figure 3 has strong policy implications. It appears that much more profit was generated by removing the heavy advertising after six

months than would have occurred by continuing it. This is because decay was so slow. However, to determine an optimal, or even a sensible, policy requires a theory of what is going on. This will

expose the assumptions that must be made to turn these measurements into decisions. Clearly, there is no shortage of practical and scientific questions here.

The experiment just described was a project within a marketing decision support operation of a large package goods company. Management asked for the experiment because of concern over advertising

budget levels. The sales data used were captured routinely from external syndicated sources and internal company records. Company management scientists analyzed the results using a high level language

and wielding a variety of standard and nonstandard statistical tools.

Whenever new measurement technologies appear, they create special opportunities for learning how the world works. Figure 4 shows data of the type that is becoming available through automated checkout

equipment in grocery stores. Shown is *dully* market share of two brands of a package good in a supermarket. The bumps are promotions. The speed and precision with which the promotion effect can be

read is portentous. Here is an indicator of opportunities for new knowledge that will become possible in the near future.
Models

Models form the other half of the models and measurements team of natural science. They provide

theories that seek to bring order to the chaos of collected

facts. They are much less well understood by laypeople

and, indeed, the word is used in enough different ways

by professionals that its meaning is often unclear.

For present purposes, I shall define a model as a

mathematical description of how something works.

Once upon a time, in a simpler age, scientists thought

they were discovering the laws of nature; thus in

physics we find Ohm's law, Newton's laws, and the

like. Unfortunately, as people subjected these laws to

closer and closer examination, they often found unset-

tling imperfections. These frequently led not to outright

rejection, but to deeper, more comprehensive theory. A

famous example is Einstein's generalization of Newto-

nian mechanics through relativity. However, after

enough incidents like this, physical scientists became

more cautious and often described their theories as

models. In more recent times, as social and manage-

ment scientists have sought to develop mathematical

understanding of their worlds, they have entertained

few illusions about the exactness of their repre-

sentations. Consequently, they have readily taken up

the terni.

There is an important practical advantage to the

incompleteness implied by the word model. Consider

the construction of a model to help solve a marketing

problem. We would wish it to include all the important

marketing phenomena required to analyze the problem,

but, equally, we would wish it to exclude extraneous

complication. This incompleteness is important and

desirable. Managers, however, are sometimes nervous

about it; they conceive that science is exact (even

though science and especially engineering abounds

with approximations). If a model is full of art, man-

FIGURE 4
Daily market shares of two national brands in a supermarket chain clearly show the effect of store specials. Data
was collected on electronic checkout equipment.

The figure shows a line graph comparing the daily market shares of two national brands, Brand A and Brand B, in a supermarket chain. The x-axis represents the day, with labels from J12 to N6. The y-axis represents the share. Brand A is represented by a solid line, and Brand B is represented by a dotted line. The graph shows fluctuations in market share over time, with notable peaks and dips for both brands.

agers become wary. They say art is just what they were

trying to get rid of by hiring expensive, overeducated

terminal thumpers.

As something of a corroboration of this mind-set,

we observe that consulting firms which say they have

discovered "laws of marketing" have sometimes had

remarkable success with high levels of management.

Managers use models all the time but without the

name. Successful management scientists working with

managers often deemphasize the word, using models as

required for the job but communicating the results as

ideas and phenomena, going into detail as requested.

One important development in this direction should

be noted by those complainers who say models are

not used in practice. Management scientists imbed

models into problem-solving systems where the models

themselves are relatively inconspicuous because they

are only a part of the final product. Silk and Urban's

(1978) ASSESSOR for evaluating new products is a

good example. It employs high technology consumer

choice models and statistical calibration, yet the

manager-client focuses on the output and its message

for his product. A similar situation arises in the models

used for audience exposure analysis of advertising

media schedules (research and frequency studies). In

such cases the client company should, and frequently

does, treat the analytic system like any other industrial

product and perform a technical evaluation of it before

using it routinely.

I would like to distinguish between model and pro-

cedure. If you allocate the advertising budget to major

markets proportional to last year's sales in those mar-

kets, you have specified a procedure. Implicit in the

procedure may or may not be a model. For example, if

you hypothesize that advertising response is propor-

tional to last year's sales times a suitably chosen func-

tion of advertising dollars, then you can construct a

model of market response that will yield as the optimal

budget allocation the same results as the described

procedure.

Thus a procedure is a way of calculating a result; a

model is a set of assumptions about how something

works. Managers frequently use procedures, usually

based in part on implicit intuitive models. Management

scientists devise procedures directly, but often try to

develop and calibrate explicit models which will gener-

ate good procedures.

In my simple world, I like to distinguish between

two types of models: good and bad. Bad models include

those that are simply wrong. For example, a model with

a linear relationship between sales and advertising has

to be incorrect. Other models are vacuous. The symbols

may not really be defined or the model may merely be a

formalistic way of saying something obvious that is

Figure 5 shows a simple customer flow model that provides a mathematical structure for estimating future sales of a new product. The model starts with a target population, which leads to awareness, then availability, and finally trial. After the trial, customers either switch to the product (US) or stick with their current product (THEM). Both groups can repeat the trial process.

better said simply. Still other models are so extraordi-

narily elaborate that they collapse of their own weight

as data and calibration requirements become so enor-

mous that testing and calibration are infeasible.

We have lived through many bad marketing models

and, if we are to continue to progress, we will have to

live through many more. At least we have good models,

too. Fortunately, it is a characteristic of science that

once you discover something worthwhile you can use it

from then on and make it a building block for con-

tinued progress.

Three types of good models are: (1) small models

offering insight and structure for thinking, (2) general

structures permitting the synthesis of a variety of

phenomena, and (3) models of new phenomena. With-

out trying to cover the whole field, I shall illustrate each

of these types.

Small Models Offering Insight: The customer flow

model displayed in Figure 5 has very much affected

people's thinking about new products in the past 15

years. Here is the basic proposition: A new product has

some intended set of customers, called its target mar-

ket. Suppose we have developed an inexpensive

gyrocompass for recreational vehicles. Recreational

vehicle owners are the target population. Before any of

them can possibly buy the product they have to be

aware of it. A company can inform people about the

existence of a new product by advertising and, in fact, any advertising agency can produce a reasonable estimate of how much money it will take to do this. For some number of millions of dollars, for

example, you can teach 20% of the American public your brand name.

But people cannot buy the product unless it is available. This is a distribution problem. Assuming a company is marketing somewhat similar goods, it will know the appropriate distribution channels

and will be able to tell what kind of availability can be achieved for the product.

Once a person in the target market is aware of the

product and has a place to buy it, the next question is will that person try the product, i.e., buy it once? Involved here is the success of advertising in communicating the product's attributes to

the prospective custonier and how the customer evaluates the desirability of those attributes. Reasonable estimates can usually be made of trial probability. In some categories of package goods,

historical norms are now available. You can also make more refined estimates by taking field measurements with the actual product. Note, however, that even without this, and long before the product

has even been made, estimates based on historical norms or managerial judgments will permit useful

FIGURE 6

An application of the marketing-mix model BRANDAID. Historical company actions and environmental conditions fed into four submodels give the outputs shown.

A figure containing four line graphs. Each graph has "Sales Index" on the y-axis and "Months" on the x-axis, ranging from 0 to 36. The first graph is labeled "seasonality and trend" and shows a fluctuating line. The second graph is labeled "retail price" and shows a relatively stable line. The third graph is labeled "advertising" and shows a slightly fluctuating line. The fourth graph is labeled "promotion" and shows a highly fluctuating line with sharp peaks and valleys.

market calculations.

Given that a person has tried the product, the next

question is whether he or she will repeat the purchase

the next time such a product is needed. Alternatively

the customer may switch to another brand. Provided

that reasonable estimates of switching and repeating

probabilities can be made, we can calculate the share of

purchases going to the new product among people who

try it once.

A straightforward calculation puts together the

whole sequence: the number of people in the target

market times the fraction who become aware of the

product times the fraction who find it available times the

fraction of those who try it times the share of purchases

that triers devote to the new brand times the sales rate

for the product class, determines the sales rate of the

new product.

The notions of awareness, availability, trial, repeat,

and switching are fundamental. These processes are

obviously going on. The model can be made very

elaborate (see Urban 1970), but the basic conceptual

structure and the process described above for calculat-

ing long-run sales rate are exceedingly simple.

The quality of that calculation will depend on the

quality of the inputs, but just using sensible numbers

helps keep the new product manager from becoming a

total dreamer. Every new product manager is a wild

advocate for his or her product. Probably this is neces-

sary since most new products fail and somebody has to

be a believer to keep from giving up before starting.

The prehistoric way to estimate new product sales was

to declare a final number in one judgmental swoop.

Amazingly, the number usually turned out to be exactly

that value which would justify continuing the develop-

ment. The discipline of putting plausible numbers into

the above calculation restricts answers to a believable

range. Then, as the company goes through the new

product development sequence, increasing investments

in field measurements narrows the uncertainty in the

final sales.

Models for Synthesis. Another useful type of model

provides a structure for assembling measurements and

phenomena from a variety of sources to solve a given

problem. An example is the marketing-mix model

BRANDAID (Little 1975). BRANDAID, when appro-

priately calibrated for a product of interest, relates

brand sales and profit to major marketing control vari-

ables, competitive actions, and environmental influ-

ences. The structure is modular so that marketing ef-

fects can be added or deleted to suit the application.

Each effect is a submodel which can be designed sepa-

rately. Major control variables such as price, promo-

tion, and advertising are premodeled, but custom ver-

sions can be substituted if desired. The number of

A line graph titled "FIGURE 7 The BRANDAID submodels are combined to track historical sales." The y-axis is labeled "Sales" and the x-axis is labeled "Months". The x-axis ranges from 0 to 36. There are two lines on the graph, one labeled "Model" and the other labeled "Actual". The lines show sales data over time.

geographic regions and competitors is flexible, from

one to whatever patience will permit.

Model calibration makes the general structure spe-

cific to a particular application. Historical data, field

experiments, econometric analysis, and whatever else

may prove useful are used to develop values for model

parameters so that the model becomes a suitable repre-

sentation of a given market.

Usually a few key variables account for most of the

effects on sales. Figures 6 and 7 show an application

employing four submodels. The submodel outputs are

plotted in Figure 6. These outputs multiply together to

give the three-year retrospective tracking shown in

Figure 7. Such a model is useful for brand planning and

sometimes even more useful for generating an antici-

pated sales rate. This becomes a standard to be com-

pared with actual sales. Discrepancies trigger diagnosis

and feedback to management.

New phenomena. It is always exciting to discover a

new phenomenon and build a model of it. This does not

happen often and, because of commercial secrecy, the

news sometimes spreads rather slowly. An example

that originated a number of years ago, but continues to

have ramifications, deals with concentration of retail

outlets. The original work was done on gasoline service

stations. All the oil companies are familiar with it, but,

as with many scientific phenomena, the principle is

more general. In this case, it carries over into other

franchise operations (e.g., branch banks and fast food

outlets) and in these industries the idea is just beginning

to take hold.

FIGURE 8

Surprisingly, as the number of service stations for a

brand in a city increases, so does the gallonage per

station.

This figure shows two curves on a graph. The x-axis is labeled "NO. STATIONS IN CITY" and the y-axis is labeled "GALLONS PER STATION". One curve, labeled "WHAT MOST PEOPLE THOUGHT", starts high and decreases as the number of stations increases. The other curve, labeled "WHAT WAS DISCOVERED", starts low and increases as the number of stations increases.

FIGURE 9

The resulting S-shaped relation between share of

market and share of stations leads to strong re-

gional brands.

This figure shows a graph with the x-axis labeled "SHARE OF STATIONS" and the y-axis labeled "SHARE OF MARKET". Both axes range from 0 to 1.0. There are two curves on the graph. One is a straight dashed line from (0,0) to (1.0, 1.0). The other is an S-shaped curve that starts below the dashed line, crosses it in the middle, and then ends above the dashed line.

The phenomenon deals with competition between

outlets in a given city. I recall sitting in the office of a

marketing economist from a major oil company and

discussing service station site location.

He said, "One thing you have to be careful about is

putting two of our stations close together or putting too

many stations in the same market. First of all, the

dealers will scream, but, in addition, you start running

into self-competition. If the company puts new stations

in a market where it already has many, it is taking

business away from itself."

This point of view is represented in Figure 8 by the

curve marked "What people thought" and shows gal-

lonage per station decreasing with number of outlets in

a city.

What Hartung and Fisher (1965) and later Naert and

Bultez (1975) did was to collect data, analyze it, and

build a theory. After filtering out a variety of variables

that confused the situation, they found that the curve

actually goes up. In other words, up to a certain point,

stations actually reinforce each other: the more stations

the company has, the greater the gallonage per station.

To me this is quite surprising, although, once a fact

is known, it is easy to offer explanations. For example,

stations are outdoor advertisements for the company;

the more stations the more people become aware of the

brand. In addition, media advertising which is hardly

worthwhile for one or two stations in a market becomes

economical if there are many. Credit cards become

more useful to a customer if the brand has many stations

and therefore will enhance total brand sales in the

market. Everything makes sense—once you know the

answer.

Figure 9 sketches the station reinforcement

phenomenon as a plot of market share versus station

share. If the effect did not exist, we would expect the

diagonal straight line. With the effect, the company

does worse than the straight line at low station share,

then with increasing station share crosses over the

diagonal, and finally bends over to unity as diminishing

returns set in.

The strategy implications of the relationship are

dramatic and quite opposite to the actions most oil

companies were taking at the time. The curve tells a

company to add stations where it is already strong, at

least up to quite a high level, whereas most companies

were trying to reach out geographically as fast as possi-

ble to become national companies with the widest pos-

sible nmarkets. As we now see, this was not the best way

to gain the most new business with new investment

dollars. (Notice, incidentally, that the oil industry is

characterized by strong regional marketers, a piece of

empirical support for the underlying phenomenon.)

Later Lilien and Rao (1976) imbedded the rein-

forcenient model into a financial model that takes into

account laydown costs, competitive pricing conditions,

building costs, total budget, etc. This provided market-

ing management with a tool to allocate service station

investment dollars to maximize long-run return,

thereby reaping the productivity of the basic discovery.
MDSS in Practice: The Bottom Line

is on Top

The best marketing decision support system I know of

grew up over several years in the major division of a

large package goods company. Although the first big

data base came on stream in mid 1972, the system is

still evolving. It has become an integral part of market-

ing operations and has materially affected management

style in several ways.

A management science group of two or three pro-

fessionals and a similar number of clerical and long-

time company people run the activity. Their online data

base contains internal company sales, records of mar-

keting activities (e.g., advertising and promotion), and

a sizeable block of syndicated data (e.g., panel and

store audit information). As a rough estimate, 10º num-

bers are online and more can be available with a few

days notice.

The system software is a high level, analytic lan-

guage which offers not only data base management, but

powerful manipulative and statistical capabilities.

Gradually, many small and large analytic routines and

models have been written and incorporated into the

system. The computer is in constant use; one or two

people are logged in virtually all the time and overnight

batch runs ordered online during the day are common.

The bread and butter business of the MDSS consists

of responding to a remarkable variety of small requests

from brand managers and higher levels or marketing

management. Rarely does raw data retrieval provide

the answer. Almost always, data are manipulated and

presented in a special way because of some issue at

hand. Service is sufficiently good with such fast turn-

around on short requests that, at one point, barriers

had to be raised to reduce requests and maintain quality

control on jobs performed. An important block of time

goes into data base maintenance and updating.
# Changes in Management Style

Two significant changes in marketing management

style can be traced to the MDSS. Tendencies toward

each had existed previously, but the MDSS permits

them to emerge in a practical way.

The first is the growth of a "try and see" approach

to new marketing programs. The marketing managers

in the company are activists who want to introduce new

ideas, but also want to know whether they really work.

A miniexperiment program has evolved. The manage-

ment science group has identified a bank of market

areas appropriate for tests. The annual marketing plan

includes a set of tests for the coming year. Extra tests

can be put in the field quickly. Typical projects are new

promotion ideas, packages, product line extensions,

and changes in advertising media strategy, copy, or

weight. The management science group has developed

analytic and evaluative routines for reading the results

quickly and efficiently. The detail, flexibility, and

rapid turnaround of the MDSS along with the experi-

ence and skill of professional people make the opera-

tion possible.

The miniexperiment program is the invention of

marketing management, not management scientists.

This has important consequences. In the first place, the

tests are sometimes not very precise. They are often

done in single markets and, as any statistician will point

out, it is difficult to estimate a standard error from one

observation. Nevertheless, the program prospers. Al-

though an individual test may be statistically weak, the

whole collection screens a considerable number of new

ideas. Real winners stand out. Run-of-the-mill im-

provements are hard to read but correspondingly less

important. As has been shown by Gross (1972) in the

case of advertising copy testing, significant gains ac-

crue to creating multiple ideas and screening them,

even if the precision is limited. It is doubtful that the

management science department would ever have pro-

posed the program on its own. The technical people

would have proposed careful multiple market experi-

ments that were more statistically defensible, but then

costs would have prevented a really extensive program.

As it is, marketing management, having invented the

idea, is willing to absorb the uncertainties of the results.

Larger scale, multiple market experiments also are

conducted. In fact, a carefully designed advertising

weights test analyzed within the MDSS recently led to a

major shift in advertising spending strategy.

The second managerial style change is a shift to-

ward regional marketing. Anyone can think up regional

strategies, but it is another matter to maintain manage-

ment control over them and do follow-up evaluations.

These are necessary to determine successes and failures

and to adjust strategies to changing conditions. The

MDSS has been critical in making this possible.
# Market Response Reporting

Conventional reviews of brand and company perfor-

mance stress status reporting, i.c., how things are. For

example, what are sales, share, price, promotion, and

advertising expenditures and what are their trends?

Status reporting is characteristic both of standard mar-

ket monitoring systems like SAMI and Nielsen and of

internal company reporting.

A more action-oriented performance review is be-

coming possible with the evolution of MDSSs. This is

market response reporting, i.e., how effective market-

ing actions are. For example, what is price elasticity,

how do sales respond to promotion, and what effect will

increased advertising have on sales?

The markets of this company have witnessed impor-

tant competitive changes over the past few years. The

historical events captured in company and syndicated

data permit extensive analysis of various marketing

tactics. Analytic methods have evolved not overnight,

but over several years to permit estimates of market

response to major changes in marketing actions. These

response estimates are the subject of ongoing reviews

similar to those conventionally made with static indi-

cators and offer marketing management new and

sharper information for decision making.

The market response information also permits pro-

jection of future performance by means of marketing-

mix models. While this is done for certain purposes, a

more important role of models has been in the historical

analysis itself. A credible model of the effects of all

major marketing variables is essential to performing the

market response analysis.
Costs/Benefits

The cost of the MDSS in this company is large in

dollars: several hundreds of thousands. As a fraction of

sales, however, the cost of the system, the data, and the

people who run it is small, perhaps 0.1%. This seems

modest considering that marketing budgets run about

5% of sales and, more important, the decisions being

affected influence sales and profit by much more. The

cost of the system and its operation splits roughly

equally among data, people, and computation.

The MDSS did not spring full blown from the

marketing vice president's head nor did it evolve with-

out controversy. Its growth has been incremental, mov-

ing from the first tentative beginnings and useful initial

results, to further extensions, more results, and so on.

This has brought certain inefficiencies ("If we'd

known then, what we know now. . . "), but the idea of

"best" at each evolutionary stage changes consid-

erably by the time of the next one so that a flexible

approach pays off.

The MDSS has used outside time-sharing services

copiously and so has been a constant target for an

inhouse data processing takeover. Yet the power, flexi-

bility, and responsiveness of languages available on

external time-sharing has not been duplicated inhouse.

Marketing management has insisted on high and in-

creasing levels of service which have only been avail-

able externally.

Some payoffs have been explicit. An analysis of

promotion led to a strategy change with a profit increase

in seven figures. Such incidents are obviously helpful

and may well be essential for survival. However, my

own feeling is that the largest benefits have come sim-

ply by facilitating good management. Bold changes of

direction in a company are infrequent (which is proba-

bly good). For the most part management deals with a

series of adjustments to conditions, no one adjustment

being particularly spectacular nor uniquely traceable to

any specific piece of data or analysis. Yet the collection

of analyses adds up to influence, decision, and im-

proved profit. Another usually unrecognized role is

assistance in preventing disasters. The pressure for

improvement in a company turns up fascinating

proposals, some of which are bound to be bad.

Analyses that lead to recommendations for inaction are

not very exciting, but are sometimes more valuable

than calls for revolution.

In summary, this particular company has developed

an effective MDSS over a multiyear period. The pro-

cess has been evolutionary with high costs, but higher

benefits. Marketing management has become more in-

novative as it receives more and better feedback from

"try and see" operations. The system has encouraged a

shift from market status reporting to market response

reporting. However, the main point to be made is that

effective MDSSs are not "pie in the sky." They are

here now.
# Problem Solving with Interactive Systems: The Grey Flannel Robot

In the early days of time-shared computers, many

people realized that a marvelous invention was at hand.

A person could have convenient access to huge com-

puters from any place with a telephone. Without too

much difficulty, a computer could interrogate the user

in a semblance of natural language, using words and

phrases to ask for input and deliver output.
# What People Thought

Clearly time-sharing was a breakthrough and the imag-

inations of the visionaries were stimulated. A new

world was forecast in which managers would sit at

terminals and formulate their problems. With the help

of easy-to-use commands, they would put key assump-

tions and judgments into the computer. These would be

incorporated into models relevant to the issues to be

examined. The managers would ask "what if" ques-

tions and evaluate various strategies. New ones would

be stimulated by the analysis. Finally the managers

would select their best alternatives and go off to take

action.
# What People Found

Managers do not like terminals. They are impatient and

busy. They do not formulate problems in model terms

because that is not the way they naturally think. They

want to think about strategy not analysis. They will

propose actions to be analyzed, but they do not want to

do it themselves.

Anecdotes to illustrate these points are many. I

recall one excruciating incident in the early days of

online models when the president of a very large corpo-

ration was invited to use the new toy hands-on. Unfor-

tunately, he couldn't type-not even with a tolerable hunt

and peck. The situation became embarrassing. Vice

presidents fluttered about. Finally a data processing

manager took over the keyboard. More fundamentally,

however, managers do not go online because of their

function and style. As Mintzberg (1973) has observed,

the manager leads a high pressure, communications-

intensive life which is much more try-and-see than

think-and-analyze.

The notion of the hands-on manager is not dead,

however. I have rather recently been told that a large

computer manufacturer has sold an elaborate informa-

tion system that will put video terminals on the desks of

10 bank vice presidents for constant use in running their

departments. I am not optimistic about the ultimate

level of use. We shall find an occasional top executive

who is an avid hands-on analyst, but I feel quite confi-

dent the majority will not be for some time to to come.
# A New Role

All is not lost, however. Interactive systems are defi-

nitely the way to go. We need only recognize that

managers work through human organizations in this as

in most things they do. What we find happening is that

individuals are emerging who can be described as *mar-*

keting science intermediaries. They are typically

OR/MS professionals or recent MBAs with good tech-

nical skills. They are first and foremost problem

solvers. They convert managers' questions into models

and analyses. They enter into dialogue with managers

and others in the organization about what the problems

really are. They provide answers to managers' ques-

tions and respond to the new questions that the answers

provoke. They build portfolios of data bases, models,

and systems to solve recurring problems. They do the

homework managers lack the time to do. They want the

manager's jobs in a few years. For the present they are

the organizers and internal consultants who build

knowledge and systems to support marketing opera-

tions.

Typically, marketing science intermediaries

program and use models and systems personally, or

with small staffs. However, they are not computer

scientists and do not report to MIS. What makes their

role possible are powerful new computer languages

available on time-sharing.
# Hardware and Software: Ready-to-Wear

Computers are impossible to work with, but are getting

better. Advances in hardware and software are pushing

the evolution of decision support systems. Hardware

manufacturing costs are dropping and prices are follow-

ing at a respectful distance. Some people forecast that

hardware costs will eventually become negligible. I am

not so sure because we are so good at thinking up big

new jobs for computers. However, it is fair to predict

that hardware cost will become a negligible part of the

computations we are doing today. Software, on the

other hand, continues to be expensive but has under-

gone advances in ways particularly relevant to us here.

The philosophy behind contemporary software is to

let the computer solve its own problems. Why should

users have to go through elaborate contortions to move

data from a statistical package to a marketing model to a

report generator? They shouldn't. Good software sys-

tems can solve these and many other machine prob-

lems, leaving the users free to concentrate on the es-

sence of the analysis. High level commands permit easy

plotting, tabling, array arithmetic, statistical analysis,

optimization, report generation, and model building,

all on the same data base.

As a user, I am most appreciative of "default"

options. Thus, if SALES is a defined data variable, I

can give a command like PLOT SALES and out

comes a plot. It fits on a 82x11 inch page, the

curve approximately fills the plot, the axes are labeled,

a sensible grid has been selected that has round-number

gradations, etc. The computer has finally become a

moderately effective clerk. If I want something dif-

ferent from default specifications, I can override them,

but most of the time, especially during exploratory

work, the automated plot is fine. Furthermore the same

commands will work on a dozen different terminals; it

is only necessary to tell the computer which one is being

used.

High level analytic languages that embody many of

these features are increasing in number and scope. An

early one with the emphasis on a concise and powerful

mathematical notation is APL. A commercial system

with a strong business orientation is EXPRESS.

Somewhat similar are PROBE, TSAM, and XSIM.

Some of the systems are easily extendable so that, for

example, FORTRAN subroutines can be easily intro-

duced as new commands. Why reinvent the wheel?

Features and degree of power vary, but all these lan-

guages try to let the analyst work an order of magnitude

faster than a FORTRAN programmer on a bare-bones,

time-sharing system.

Most of the observations just made about interac-

tive systems extend well beyond the context of market-

ing (see for example, Keen and Scott Morton 1978).
# Implementation: Which Way Is Up?

Any attempt to install an MDSS has organizational

ramifications. Will marketing management's an-

tibodies reject the graft? Will the internal computer

establishment gag?

Taking these issues in order, consider Argyris'

view (1971) in *Management Science*:

If management Information systems achieve their designers'

highest aspirations, they will tend to create conditions where

executives will experience: (1) reduction of space of free

movement, (2) psychological failure and double blind, (3)

leadership based more on competence than formal power, (4)

decreased feelings of essentiality. These experiences will

tend to create genuine resistance to MIS.

Another hand-wringer. I do not agree and will argue

otherwise, but first let me give an anecdote to favor

Argyris' view. A marketing vice president I know re-

fused to conduct a field experiment which would have

sought to measure the effect of advertising on sales. He

had various reasons for his position, but I suspect the

real reason was that he had negotiated an increased

advertising budget with the president. Therefore, if the

experiment should confirm the increased budget, it

would be redundant and, if not, he would look bad. So

why do the experiment? To use Argyris' words, better

information only restricted his space of free movement.

I believe that the executive was wrong and that by

such actions his company could lose competitive ad-

vantage which would eventually reflect on him. How-

ever, this type of managerial reaction certainly exists.

A better style, in my opinion, is to view the advertising

increase as an opportunity for measurement and further

adaptation to the market.

Such examples notwithstanding, my main observa-

tion is that it takes a first class marketing manager to

bring an MDSS into being in the first place and such

people are not about to let their systems run them. On

the contrary it gives them a feeling of power to act on

moderately reliable information for a change.

Let's check other commentators on the MIS scene.

Gruber and Niles (1976) write:

Understanding what managers actually do and...organizing

the information they currently use is the only way to build

relevancy... the biggest mistake in... current... work is

that it. builds products that serve some assumed

decision making process which real managers do not carry

out.

I agree in part, but we have gone past this stage. To

support their point, I recall a director of marketing who

was very impressed with computer technology and de-

cided he wanted instant retrieval. His idea was to have a

video terminal on his desk so that, if he wanted to know

sales last month in Buffalo, he could press a button and,

presto, the data would appear.

We told him, "It's not really retrieval you want but

models," and explained why.

He said, "OK, you people are the experts not me."

So we gave him models. It turned out that he wanted

retrieval. We went back and gave him retrieval. Actu-

ally, what we gave him was retrieval plus analysis plus

models, and even more important, he hired a marketing

science intermediary. This particular marketing di-

rector was not about to push any buttons that did not

have people on the other end of the wire.

Gruber and Niles' point about doing better and

faster whatever is being done now is a good one and an

excellent way to build credibility and support for an

MDSS. However, we are well beyond that in many

areas and have plenty of examples of new and useful

analysis, measurements, and models. A variety of these

have been discussed already.

A major issue for an MDSS is its relation to inhouse

data processing and management information systems.

The first 10 years of business applications of time-

sharing have been dominated by external vendors. In

this period, fixed costs of time-sharing have been high

because of hardware, software, communication

equipment, and marketing. Much of the marketing has

really been low level applications consulting. The costs

and required skills have deterred inhouse time-sharing time

in many organizations. Furthermore, inhouse data pro-

cessing typically has had its hands full meeting its

current operational commitments. As a result, most ac-

tivities that look like MDSSs have been done on outside

time-sharing. Yet, inhouse data processing depart-

ments, which typically live in an environment of repeti-

tive batch jobs, frequently consider the cost of com-

mercial time-sharing to be exorbitant. Marketing man-

agement, however, has not found the cost high relative

to the value of the tasks performed and has preferred to

pay an apparent premium rather than wait for specially

progranımed batch runs or, in some cases, deal with

cumbersome, leanly serviced, inhouse time-sharing

systems.

The scene continues to change with two rather dif-

ferent patterns now in evidence. On the one hand,

central MIS is in some cases becoming a better time-

sharing vendor, bringing in good operating systems and

languages. It thus becomes a bigger supplier of com-

putations, but one with less concern about the content

of the computation, since the usage is decentralized. In

our case, this would be done by a marketing science

intermediary working for the marketing department.

Another and perhaps more significant development

is the decentralization made possible by the increasing

power of minicomputers. Small computers with high

level analytic languages can be installed in the func-

tional department and only interconnect with MIS to

pick up or deposit data. Costs are moderate and techni-

cal support requirements manageable. If these ma-

chines and their software prove reasonably robust, the

growth of decentralized MDSSs seems very likely..
# Summary: Whither Decision Support?

The main thrust of this paper is to say that marketing

management can, and should, obtain better analytic

help for its planning and operations. This can be done

by a marketing decision support system that puts the

new technology of computers and marketing science to

work on increasing marketing productivity. An MDSS

means hiring people with marketing science skills. It

means organizing data bases and putting them in usable

form. It means building a portfolio of models and

analytic techniques directed at important company is-

sues. It means integrating problem-solving and

problem-finding within the marketing function using

the marketing science intermediary to facilitate the pro-

cess. A strong system does not spring up overnight. It

takes two or three years of evolution and development,

but it can lead to new styles of marketing management.

Let's look ahead. In the next five to 10 years, 1

foresee:

*   An order of magnitude increase in the amount of

marketing data used. Through MDSS develop-

ment, the internal data of a company will finally

become accessible on a rather detailed basis:

sales, advertising, promotion, etc. Automati-

cally collected point-of-sale information from

the marketplace (e.g., Universal Product Code

data from supermarkets) will replace most cur-

rent store audits. Much better longitudinal data

on customers (e.g., panels) will be generally

available and will include such currently missing

information as media use. The monitoring of

competitive advertising, promotion, and price

will be vastly improved.

*   A similar tenfold increase in computer power

available for marketing analysis. The hardware

is already built; it is out there and purchasable.

The price is going to break. The only problem

will be for marketing to absorb computer power

in a useful way.

*   Widespread adoption of analytic computer lan-

guages. These make data accessible and greatly

facilitate analysis. Some exist now, more will be

introduced, and all will improve.

*   A shift from market status reporting to market

response reporting. This is an important change.

SAMI, Nielsen, and other market monitoring

systems, including internal sales reporting, em-

phasize market status, i.e., how things are: what

are sales, share, price, advertising, etc.?

Tomorrow's systems will report response,

i.e., how things react: what's price elasticity,

advertising response, promotional effectiveness,

etc.? Companies will even do a reasonably good

job of monitoring competitor's market response.

Much work lies ahead for marketing scien-

tists in order for this to come to pass. We need

well-designed data sources and many new tools.

How do we handle eclectic data sources in devel-

oping: and calibrating models? What are the best

underlying models to represent marketing

phenomena? We can expect a flowering of new

work.

*   New methodology for supporting strategy devel-

opment. Marketing scientists will further ad-

vance our understanding of product-market

boundaries. Better response measurements will

expose more clearly the nature of competitive

interaction and give rise to game theoretic strat-

egy development.

And, finally, I foresee:

*   A shortage of marketing scientists. You know

what that means: higher salaries, more fun, excit-

ing new toys. From this I conclude that market-

ing is the right field to be in.

Argyris, Chris (1971), "Management Information Systems: The

Challenge to Rationality and Emotionality," Management Scl-

ence, 17 (February), B275-292.

Bass, F.M. and D.G. Clarke (1972), "Testing Distributive Lag

Models of Advertising Effect," Journal of Marketing Research,

9 (August), 298-308.

Bloom, D. and M.J. Stewart (1977), "An Integrated Marketing

Planning System," Proceedings of ESOMAR Conference, (Feb-

ruary), 168-186.

Business Week (1973), "Ten Year Experience at General Foods,"

(August 25), 48-55.

Cox, K.K., J.B. Higginbotham, and J. Burton (1976), "Applica-

tions of Focus Group Interviews in Marketing," Journal of

Marketing, 40 (January), 77-80.

Day, George S. (1977), "Diagnosing the Product Portfolio," Jour-

nal of Marketing, 41 (April), 29-38.
REFERENCES

Decision Support Systems for Marketing Managers / 25

Ehrenberg, A.S.C. (1972), Repeat Buying, New York: American

Elsevier.

Gorry, G. Anthony and Michael S. Scott Morton (1971), "A

Framework for Management Information Systems," Sloan

Management Review, 13 (Fall), 55-70.

Grayson, C. Jackson Jr. (1973), "Management Science and Busi-

ness Practice," Harvard Business Review, 51 (July-August),

41-48.

Green, Paul E. and Yoram Wind (1975), "New Way to Measure

Consumers' Judgments," Harvard Business Review, 53 (July-

August), 107-117.

Gross, Irwin (1972), "The Creative Aspects of Advertising,"

Sloan Management Review, 14 (Fall), 83-109.

—— (1977), "The Value of 'Value-in-use,' " unpublished

note, Wilmington, DE: DuPont Company.

Gruber, William, H. and John S. Niles (1976), The New Manage-

ment, New York: McGraw-Hill, 138-139.

Hartung, Philip H. and James L. Fisher (1965), "Brand Switching

and Mathematical Programming in Market Expansion," Man-

agement Science, 11 (August), B231-243.

Hauser, John R. (1978), "Testing the Accuracy, Usefulness, and

Significance of Probabilistic Choice Models: An Information

Theoretic Approach," Operations Research, 26 (May-June),

406-421.

—— and Glen L. Urban (1977), "A Normative Methodology

for Modeling Consumer Response in Innovation," Operations

Research, 25 (July-August), 576-619.

Hess, Sidney W. (1967), "The Use of Models in Marketing Timing

Decisions," Operations Research, 15 (July-August), 720-737.

von Hippel, Eric (1978), "Successful Industrial Products from

Customer Ideas," Journal of Marketing, 42 (January), 39-49.

Keen, Peter G.W. and Michael S. Scott Morton (1978), Decision

Support Systems: An Organizational Perspective, Reading,

MA: Addison-Wesley.

Lilien, Gary L. and Ambar G. Rao (1976), "A Model for Allocat-

ing Retail Outlet Building Resources Across Market Areas,"

Operations Research, 24 (January-February), 1-14.

Little, John D.C. (1970), "Models and Managers: The Concept of a

Decision Calculus," Management Science, 16 (April), B466-

485.

——(1975), "BRANDAID: A Marketing-Mix Model, Parts I

and," Operations Research, 23 (July-August), 628-673.

Mintzberg, Henry (1973), The Nature of Managerial Work, New

York: Harper and Row.

Montgomery, David B. and Glen L. Urban (1969), Management

Science in Marketing, Englewood Cliffs, NJ: Prentice-Hall, Inc.

Naert, Philippe A. and Alain V. Bultez (1975), "A Model of

Distribution Network Aggregate Performance," Management

Science, 21 (June), 1102-1112.

Nigam, A.K., ed. (1975,76,77), Special Issues on Practice, Inter-

faces, 6 (November), 7 (November), 8 (November), Part 2.

Parfitt, J.H. and B.J.K. Collins (1968), "Use of Consumer Panels

for Isrand-Share Prediction," Journal of Marketing Research, 5

(May), 131-145.

Parsons, Leonard J. and Randall L. Schultz (1976), Marketing

Models and Econometric Research, Amsterdam: North Hol-

land.

Prince, George M. (1972), The Practice of Creativity, New York:

Mac Millan.

Silk, Alvin J. and Glen L. Urban (1978), "Pre-Test Market Evalua-

tion of New Packaged Goods: A Model and Measurement Meth

odology," Journal of Marketing Research, 15 (May), 171-191.

Shocker, A.D. and V. Srinivasan (1977), "Multiattribute Ap-

prouches for Concept Evaluation and Generation: A Critical

Review," working paper no. 240 (October), Pittsburgh:

Gra luate School of Business, University of Pittsburgh.

Urban, Glen L. (1970), "SPRINTER Mod III: A Model for the

Analysis of New Frequently Purchased Consun.er Products,"

Operations Research, 18 (September-October), 805-854.
